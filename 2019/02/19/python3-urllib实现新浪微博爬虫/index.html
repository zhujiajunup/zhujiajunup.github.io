<!doctype html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="baidu-site-verification" content="v9LXQCpSna">


<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">












  
  
    
  
  <link href="//cdn.jsdelivr.net/fancybox/2.1.5/jquery.fancybox.min.css" rel="stylesheet" type="text/css">




  
  
  
  

  
    
    
  

  
    
      
    

    
  

  

  
    
      
    

    
  

  
    
      
    

    
  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Lobster Two:300,300italic,400,400italic,700,700italic|consolas:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






  

<link href="//maxcdn.bootstrapcdn.com/font-awesome/4.6.2/css/font-awesome.min.css" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css">


  <meta name="keywords" content="爬虫,python,新浪微博,urllib,">








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0">






<meta name="description" content="前言（一些废话）最近试了一下网页版的(weibo.com)和移动端的(m.weibo.cn)，网页版的解析一大堆网页实在是太麻烦，移动端只需要请求，直接返回json数据，这里对这两种方式做了下优缺点对比 网页版 优点   用户信息获取的很全面，出生日期、性取向、感情状况是移动端不能获取的 微博、粉丝可以抓取的比较全面 可以学习xpath、bs4、正则的网页解析   缺点   要花钱哦，因为多账号登">
<meta name="keywords" content="爬虫,python,新浪微博,urllib">
<meta property="og:type" content="article">
<meta property="og:title" content="python3+urllib实现新浪微博爬虫">
<meta property="og:url" content="https://zhujiajunup.cn/2019/02/19/python3-urllib实现新浪微博爬虫/index.html">
<meta property="og:site_name" content="zhujiajunup">
<meta property="og:description" content="前言（一些废话）最近试了一下网页版的(weibo.com)和移动端的(m.weibo.cn)，网页版的解析一大堆网页实在是太麻烦，移动端只需要请求，直接返回json数据，这里对这两种方式做了下优缺点对比 网页版 优点   用户信息获取的很全面，出生日期、性取向、感情状况是移动端不能获取的 微博、粉丝可以抓取的比较全面 可以学习xpath、bs4、正则的网页解析   缺点   要花钱哦，因为多账号登">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://i.imgur.com/dE9BHMw.png">
<meta property="og:image" content="http://i.imgur.com/QuNbY4N.png">
<meta property="og:image" content="http://i.imgur.com/dHe17JD.png">
<meta property="og:image" content="http://i.imgur.com/KltTfzw.png">
<meta property="og:image" content="http://i.imgur.com/peZuxWD.png">
<meta property="og:image" content="http://i.imgur.com/DnbYiPC.png">
<meta property="og:image" content="http://i.imgur.com/Bx5xC4C.png">
<meta property="og:updated_time" content="2019-02-19T09:26:07.073Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="python3+urllib实现新浪微博爬虫">
<meta name="twitter:description" content="前言（一些废话）最近试了一下网页版的(weibo.com)和移动端的(m.weibo.cn)，网页版的解析一大堆网页实在是太麻烦，移动端只需要请求，直接返回json数据，这里对这两种方式做了下优缺点对比 网页版 优点   用户信息获取的很全面，出生日期、性取向、感情状况是移动端不能获取的 微博、粉丝可以抓取的比较全面 可以学习xpath、bs4、正则的网页解析   缺点   要花钱哦，因为多账号登">
<meta name="twitter:image" content="http://i.imgur.com/dE9BHMw.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"right","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 'undefined',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://zhujiajunup.cn/2019/02/19/python3-urllib实现新浪微博爬虫/">





<script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
<link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet">
<style>
    .pace .pace-progress {
        background: #1E92FB; /*进度条颜色*/
        height: 3px;
    }
    .pace .pace-progress-inner {
         box-shadow: 0 0 10px #1E92FB, 0 0 5px     #1E92FB; /*阴影颜色*/
    }
    .pace .pace-activity {
        border-top-color: #1E92FB;    /*上边框颜色*/
        border-left-color: #1E92FB;    /*左边框颜色*/
    }
</style>


  <title> python3+urllib实现新浪微博爬虫 | zhujiajunup </title>
</head>

  	 <!-- custom analytics part create by xiamo -->
<script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
<script>AV.initialize("kJ2sJuSJeByLioULSXrJ5CSq-9Nh9j0Va", "uBWeNxCbFEWsOVDTmAInrDq3");</script>
<script>
function showTime(Counter) {
	var query = new AV.Query(Counter);
	$(".leancloud_visitors").each(function() {
		var url = $(this).attr("id").trim();
		query.equalTo("url", url);
		query.find({
			success: function(results) {
				if (results.length == 0) {
					var content = $(document.getElementById(url)).text() + ': 0';
					$(document.getElementById(url)).text(content);
					return;
				}
				for (var i = 0; i < results.length; i++) {
					var object = results[i];
					var content = $(document.getElementById(url)).text() + ': ' + object.get('time');
					$(document.getElementById(url)).text(content);
				}
			},
			error: function(object, error) {
				console.log("Error: " + error.code + " " + error.message);
			}
		});

	});
}

function addCount(Counter) {
	var Counter = AV.Object.extend("Counter");
	url = $(".leancloud_visitors").attr('id').trim();
	title = $(".leancloud_visitors").attr('data-flag-title').trim();
	var query = new AV.Query(Counter);
	query.equalTo("url", url);
	query.find({
		success: function(results) {
			if (results.length > 0) {
				var counter = results[0];
				counter.fetchWhenSave(true);
				counter.increment("time");
				counter.save(null, {
					success: function(counter) {
						var content = $(document.getElementById(url)).text() + ': ' + counter.get('time');
						$(document.getElementById(url)).text(content);
					},
					error: function(counter, error) {
						console.log('Failed to save Visitor num, with error message: ' + error.message);
					}
				});
			} else {
				var newcounter = new Counter();
				newcounter.set("title", title);
				newcounter.set("url", url);
				newcounter.set("time", 1);
				newcounter.save(null, {
					success: function(newcounter) {
					    console.log("newcounter.get('time')="+newcounter.get('time'));
						var content = $(document.getElementById(url)).text() + ': ' + newcounter.get('time');
						$(document.getElementById(url)).text(content);
					},
					error: function(newcounter, error) {
						console.log('Failed to create');
					}
				});
			}
		},
		error: function(error) {
			console.log('Error:' + error.code + " " + error.message);
		}
	});
}
$(function() {
	var Counter = AV.Object.extend("Counter");
	if ($('.leancloud_visitors').length == 1) {
		addCount(Counter);
	} else if ($('.post-title-link').length > 1) {
		showTime(Counter);
	}
});
</script>
  
<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  



  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?34b88e41cb294e46af8e27b8c1cf5508";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>








  
  
    
  

  <div class="container one-collumn sidebar-position-right page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta custom-logo">
  

  <div class="custom-logo-site-title">
    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">zhujiajunup</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
    
      <h1 class="site-subtitle" itemprop="description"></h1>
    
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  
  
  
  

  <article class="post post-type-normal " itemscope="" itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="https://zhujiajunup.cn/2019/02/19/python3-urllib实现新浪微博爬虫/">

  <span style="display:none" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
    <meta itemprop="name" content="zhujiajunup">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/head.jpg">
  </span>

  <span style="display:none" itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="zhujiajunup">
    <span style="display:none" itemprop="logo" itemscope="" itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="zhujiajunup" src="/images/avatar.jpg">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
            
            
              
                python3+urllib实现新浪微博爬虫
              
            
          </h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-02-19T17:25:22+08:00">
                2019-02-19
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/python/" itemprop="url" rel="index">
                    <span itemprop="name">python</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/python/爬虫/" itemprop="url" rel="index">
                    <span itemprop="name">爬虫</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
		  
			 
          
          
             <span id="/2019/02/19/python3-urllib实现新浪微博爬虫/" class="leancloud_visitors" data-flag-title="python3+urllib实现新浪微博爬虫">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">热度 </span>
               
                 <span class="leancloud-visitors-count"></span>
				 <span>℃</span>
             </span>
          
		   
          

		  
            <div class="post-wordcount">
              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计</span>
                
                <span title="字数统计">
                  1.6k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长</span>
                
                <span title="阅读时长">
                  6
                </span>
              
            </div>
          
		  
          
 
        


        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="前言（一些废话）"><a href="#前言（一些废话）" class="headerlink" title="前言（一些废话）"></a>前言（一些废话）</h1><p>最近试了一下网页版的(<a href="http://weibo.com/" target="_blank" rel="noopener">weibo.com</a>)和移动端的(<a href="http://m.weibo.cn/" target="_blank" rel="noopener">m.weibo.cn</a>)，网页版的解析一大堆网页实在是太麻烦，移动端只需要请求，直接返回json数据，这里对这两种方式做了下优缺点对比</p>
<h2 id="网页版"><a href="#网页版" class="headerlink" title="网页版"></a>网页版</h2><ul>
<li>优点</li>
</ul>
<ol>
<li>用户信息获取的很全面，出生日期、性取向、感情状况是移动端不能获取的</li>
<li>微博、粉丝可以抓取的比较全面</li>
<li>可以学习xpath、bs4、正则的网页解析</li>
</ol>
<ul>
<li>缺点</li>
</ul>
<ol>
<li>要花钱哦，因为多账号登录需要验证码，验证码识别的话，用云打码（没用过）是收费的</li>
<li>解析页面恶心的一批，要写正则、要去看网页…比较麻烦</li>
</ol>
<h2 id="移动版"><a href="#移动版" class="headerlink" title="移动版"></a>移动版</h2><ul>
<li>优点</li>
</ul>
<ol>
<li>不需要验证码</li>
<li>直接解析json</li>
</ol>
<ul>
<li>缺点</li>
</ul>
<ol>
<li>个人信息不全</li>
<li>微博、粉丝分页到了250之后，就没有数据返回了，暂时还没解决这个是为什么。</li>
</ol>
<p>现在用的是移动版，配了5个微博账号，5个线程在跑，电脑扔在寝室跑，不敢说一天多少多少数据，但现在保持在一天用户30W、微博20W左右的数据量…只跑了两天…</p>
<p>源码的话，看后面….</p>
<h1 id="正题"><a href="#正题" class="headerlink" title="正题"></a>正题</h1><p>其实思路很简单，就是通过urllib模拟请求登录、发请求，然后解析json，存数据库…当然程序还有很多优化的地方，以后慢慢改进</p>
<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><ul>
<li>python3</li>
<li>django 1.11.3</li>
<li>mysql 5.7.17</li>
<li>fiddler 4</li>
</ul>
<h2 id="抓取"><a href="#抓取" class="headerlink" title="抓取"></a>抓取</h2><p>写爬虫的套路就是，访问页面，分析页面行为，也就是页面的每一个操作都发了什么样的请求，返回了什么数据，记住这个套路，还有什么爬虫不能写。</p>
<h3 id="模拟登陆"><a href="#模拟登陆" class="headerlink" title="模拟登陆"></a>模拟登陆</h3><p>打开<a href="http://m.weibo.cn" target="_blank" rel="noopener">m.weibo.cn</a>，打开fiddler 4，开启https请求的捕捉，不知道怎么开自行google<br>当你输入好账号、密码点击登录的时候，看fiddler4捕获的请求</p>
<p><img src="http://i.imgur.com/dE9BHMw.png" alt=""></p>
<p><img src="http://i.imgur.com/QuNbY4N.png" alt=""><br>post请求，当然是看看他发了什么数据啦….</p>
<p><img src="http://i.imgur.com/dHe17JD.png" alt=""></p>
<p>再看看response的数据</p>
<p><img src="http://i.imgur.com/KltTfzw.png" alt=""><br>返回了用户登录的状态，uid…<br>你可以访问 www://weibo.com/u/ + 上图的uid加一波微博关注（真无耻，强行吸粉）</p>
<p>密码没有做任何加密处理，嘻嘻，很简单吧，现在只要模拟个post请求就行了。是不是很简单？</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">def login(user_name, password, opener):</span><br><span class="line">    LOGGER.info(user_name + &apos; login&apos;)</span><br><span class="line">    args = &#123;</span><br><span class="line">        &apos;username&apos;: user_name,</span><br><span class="line">        &apos;password&apos;: password,</span><br><span class="line">        &apos;savestate&apos;: 1,</span><br><span class="line">        &apos;ec&apos;: 0,</span><br><span class="line">        &apos;pagerefer&apos;: &apos;https://passport.weibo.cn/signin/&apos;</span><br><span class="line">                     &apos;welcome?entry=mweibo&amp;r=http%3A%2F%2Fm.weibo.cn%2F&amp;wm=3349&amp;vt=4&apos;,</span><br><span class="line">        &apos;entry&apos;: &apos;mweibo&apos;,</span><br><span class="line">        &apos;wentry&apos;: &apos;&apos;,</span><br><span class="line">        &apos;loginfrom&apos;: &apos;&apos;,</span><br><span class="line">        &apos;client_id&apos;: &apos;&apos;,</span><br><span class="line">        &apos;code&apos;: &apos;&apos;,</span><br><span class="line">        &apos;qq&apos;: &apos;&apos;,</span><br><span class="line">        &apos;hff&apos;: &apos;&apos;,</span><br><span class="line">        &apos;hfp&apos;: &apos;&apos;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    post_data = urllib.parse.urlencode(args).encode()</span><br><span class="line">    try_time = 0</span><br><span class="line">    while try_time &lt; constants.TRY_TIME:</span><br><span class="line">        try:</span><br><span class="line">            resp = opener.open(constants.LOGIN_URL, post_data)</span><br><span class="line">            resp_json = json.loads(resp.read().decode())</span><br><span class="line">            if &apos;retcode&apos; in resp_json and resp_json[&apos;retcode&apos;] == &apos;20000000&apos;:</span><br><span class="line">                LOGGER.info(&quot;%s login successful&quot; % user_name)</span><br><span class="line">                break</span><br><span class="line">            else:</span><br><span class="line">                LOGGER.warn(&apos;login fail:%s&apos; % str(resp_json))</span><br><span class="line">                sleep(10)</span><br><span class="line">                try_time += 1</span><br><span class="line">        except :</span><br><span class="line">            LOGGER.error(&quot;login failed&quot;)</span><br><span class="line">            LOGGER.error(traceback.print_exc())</span><br><span class="line">            sleep(10)</span><br><span class="line">            try_time += 1</span><br><span class="line">            LOGGER.info(&apos;try %d time&apos; % try_time)</span><br></pre></td></tr></table></figure>
<p>看看写的模拟登录能不能用，当然要测试啦，这个测试当然是你自己写啦，反正我已经测试过了，如果不出意外的话，你的测试会不通过，如下URLError<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;E:\codingspace\python\Jpider\spiders\weibo\weibo_http.py&quot;, line 40, in login</span><br><span class="line">    resp = opener.open(constants.LOGIN_URL, post_data)</span><br><span class="line">  File &quot;D:\ProgramData\Anaconda3\lib\urllib\request.py&quot;, line 526, in open</span><br><span class="line">    response = self._open(req, data)</span><br><span class="line">  File &quot;D:\ProgramData\Anaconda3\lib\urllib\request.py&quot;, line 544, in _open</span><br><span class="line">    &apos;_open&apos;, req)</span><br><span class="line">  File &quot;D:\ProgramData\Anaconda3\lib\urllib\request.py&quot;, line 504, in _call_chain</span><br><span class="line">    result = func(*args)</span><br><span class="line">  File &quot;D:\ProgramData\Anaconda3\lib\urllib\request.py&quot;, line 1361, in https_open</span><br><span class="line">    context=self._context, check_hostname=self._check_hostname)</span><br><span class="line">  File &quot;D:\ProgramData\Anaconda3\lib\urllib\request.py&quot;, line 1320, in do_open</span><br><span class="line">    raise URLError(err)</span><br><span class="line">urllib.error.URLError: &lt;urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:749)&gt;</span><br></pre></td></tr></table></figure></p>
<p>哎呀，好烦，又报错，怎么办呢，stackoverflow欢迎你，传送门<a href="https://stackoverflow.com/" target="_blank" rel="noopener">https://stackoverflow.com/</a>，有错自己查，stackoverflow能解决99%你遇到的问题。</p>
<h2 id="关注信息抓取"><a href="#关注信息抓取" class="headerlink" title="关注信息抓取"></a>关注信息抓取</h2><p>登录就那么轻松的搞定了，用户信息、微博、粉丝、关注的套路都是一样，分析拦截的请求，看哪个请求是返回数据的，然后自己模拟这个请求，就ok啦。</p>
<p>这里就只做用户关注的抓取示例，其他的自己去依葫芦画瓢。<br>最近在看环法，自己也是个骑行爱好者…现在天热…都不能出去骑了，很绝望。<br>就以<a href="https://m.weibo.cn/u/5901021570" target="_blank" rel="noopener">环法自行车赛</a>这个用户的关注信息为例吧</p>
<p><img src="http://i.imgur.com/peZuxWD.png" alt=""></p>
<p>现在你可以借助chrome的工具栏看请求，windows下的快捷键是F12</p>
<p>查看他的关注-&gt;全部关注。你会发现浏览器发了如下的请求<br><img src="http://i.imgur.com/DnbYiPC.png" alt=""></p>
<p>你可以直接复制这个请求，在浏览器上打开。</p>
<p><img src="http://i.imgur.com/Bx5xC4C.png" alt=""></p>
<p>可以看到这个请求返回的就是他的关注用户的json数据，而python中的json模块直接解析，很方便吧。</p>
<p>看看这个url[<a href="https://m.weibo.cn/api/container/getIndex?containerid=231051_-_followers_-_5901021570&amp;luicode=10000011&amp;lfid=1005055901021570&amp;featurecode=20000320&amp;type=uid&amp;value=5901021570" target="_blank" rel="noopener">点开试试?</a>]<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://m.weibo.cn/api/container/getIndex?containerid=231051_-_followers_-_5901021570&amp;luicode=10000011&amp;lfid=1005055901021570&amp;featurecode=20000320&amp;type=uid&amp;value=5901021570</span><br></pre></td></tr></table></figure></p>
<p>该用户的uid为5901021570，url是怎么拼的不用再多说了吧。</p>
<p>当然还有分页，自己往下拖，你可以看到url上会多了个page的参数，那个就是页号</p>
<p>数据都拿到了，还等什么？解析完后想怎么存怎么存吧。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">def grab_user_follower(self, user_id):</span><br><span class="line">    opener = weibo_http.get_openner()</span><br><span class="line">    user = self.grab_user(user_id)</span><br><span class="line">    att_num = user.attNum</span><br><span class="line">    max_page = int(int(att_num) / 20)</span><br><span class="line">    page = 1</span><br><span class="line">    while page &lt;= max_page:</span><br><span class="line">        resp = opener.open(constants.FOLLOWER_URL_PATTERN % (user_id, user_id, str(page)))</span><br><span class="line">        self.logger.info(constants.FOLLOWER_URL_PATTERN % (user_id, user_id, str(page)))</span><br><span class="line">        r = resp.read()</span><br><span class="line">        resp_json = json.loads(r.decode())</span><br><span class="line">        if &apos;msg&apos; in resp_json:</span><br><span class="line">            break</span><br><span class="line">        for card in resp_json[&apos;cards&apos;]:</span><br><span class="line"></span><br><span class="line">            for cg in filter(lambda c: &apos;user&apos; in c, card[&apos;card_group&apos;]):</span><br><span class="line">                follower = dao.save_user_info(cg[&apos;user&apos;])</span><br><span class="line">                dao.save_relationship(follower, user)</span><br><span class="line">                self.id_enqueue(follower.id, self.user_set_lock, self.CRAWLED_USERS, self.user_queue)</span><br><span class="line">        page += 1</span><br></pre></td></tr></table></figure>
<h2 id="后语"><a href="#后语" class="headerlink" title="后语"></a>后语</h2><p>关于微博移动端的抓取就暂时说这么多吧，说实话，移动端还是比较简单的，多线程可以搞定，只开了五个，日抓取量已经达到了30W用户+20W微博了，之后打算改成分布式的…</p>
<p>关于源码，暂时还没想放出来，因为不开心,而且我觉得这个也没什么难度，基本可以自己动手写，单线程写完再改成多线程的，很easy的…</p>
<p>当然我已经放在github了，地址暂时先不放，考验你找资料的能力了….</p>
<p>过几天再把网页版的抓取过程放上来，心情好点再说…</p>

      
    </div>

    <div>
      
        

      
    </div>
  
        <div class="post-tags">
          
            <a href="/tags/爬虫/" rel="tag"># 爬虫</a>
          
            <a href="/tags/python/" rel="tag"># python</a>
          
            <a href="/tags/新浪微博/" rel="tag"># 新浪微博</a>
          
            <a href="/tags/urllib/" rel="tag"># urllib</a>
          
        </div>
      


    <div>
     
    </div>


    <footer class="post-footer">
        
     <div>    
      
      <ul class="post-copyright">
         <li class="post-copyright-link">
          <strong>本文作者：</strong>
          <a href="/" title="欢迎访问 zhujiajunup 的个人博客">zhujiajunup</a>
        </li>

        <li class="post-copyright-link">
          <strong>本文标题：</strong>
          <a href="https://zhujiajunup.cn/2019/02/19/python3-urllib实现新浪微博爬虫/" title="python3+urllib实现新浪微博爬虫">python3+urllib实现新浪微博爬虫</a>
        </li>

        <li class="post-copyright-link">
          <strong>本文链接：</strong>
          <a href="https://zhujiajunup.cn/2019/02/19/python3-urllib实现新浪微博爬虫/" title="python3+urllib实现新浪微博爬虫">https://zhujiajunup.cn/2019/02/19/python3-urllib实现新浪微博爬虫/</a>
        </li>

        <li class="post-copyright-date">
            <strong>发布时间：</strong>2019年2月19日 - 17时02分
        </li>  

        <li class="post-copyright-license">
          <strong>版权声明： </strong>
          本文由 zhujiajunup 原创，采用 <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/deed.zh" rel="license" target="_blank">保留署名-非商业性使用-禁止演绎 4.0-国际许可协议</a> <br>转载请保留以上声明信息！
        </li>
      </ul>
    
  </div>  
      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/02/19/CountDownLatch用法浅析/" rel="next" title="CountDownLatch用法浅析">
                <i class="fa fa-chevron-left"></i> CountDownLatch用法浅析
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/02/19/spring-boot-多模块简单示例/" rel="prev" title="spring boot 多模块简单示例">
                spring boot 多模块简单示例 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>

          
          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="lv-container" data-id="city" data-uid="MTAyMC8zMjI4My84ODQ3"></div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image" src="/images/head.jpg" alt="zhujiajunup">
          <p class="site-author-name" itemprop="name">zhujiajunup</p>
          <p class="site-description motion-element" itemprop="description"></p>
        </div>
        <nav class="site-state motion-element">
        
          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">8</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">12</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">17</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/zhujiajunup" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/47452014" target="_blank" title="weibo">
                  
                    <i class="fa fa-fw fa-weibo"></i>
                  
                  weibo
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              友情链接
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="https://github.com/zhujiajunup" title="Github" target="_blank">Github</a>
                </li>
              
            </ul>
          </div>
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#前言（一些废话）"><span class="nav-number">1.</span> <span class="nav-text">前言（一些废话）</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#网页版"><span class="nav-number">1.1.</span> <span class="nav-text">网页版</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#移动版"><span class="nav-number">1.2.</span> <span class="nav-text">移动版</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#正题"><span class="nav-number">2.</span> <span class="nav-text">正题</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#环境"><span class="nav-number">2.1.</span> <span class="nav-text">环境</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#抓取"><span class="nav-number">2.2.</span> <span class="nav-text">抓取</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#模拟登陆"><span class="nav-number">2.2.1.</span> <span class="nav-text">模拟登陆</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#关注信息抓取"><span class="nav-number">2.3.</span> <span class="nav-text">关注信息抓取</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#后语"><span class="nav-number">2.4.</span> <span class="nav-text">后语</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">zhujiajunup</span>
</div>






        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  




  
  <script type="text/javascript" src="//cdn.jsdelivr.net/jquery/2.1.3/jquery.min.js"></script>

  
  <script type="text/javascript" src="//cdn.jsdelivr.net/fastclick/1.0.6/fastclick.min.js"></script>

  
  <script type="text/javascript" src="//cdn.jsdelivr.net/jquery.lazyload/1.9.3/jquery.lazyload.min.js"></script>

  
  <script type="text/javascript" src="//cdn.jsdelivr.net/velocity/1.2.3/velocity.min.js"></script>

  
  <script type="text/javascript" src="//cdn.jsdelivr.net/velocity/1.2.3/velocity.ui.min.js"></script>

  
  <script type="text/javascript" src="//cdn.jsdelivr.net/fancybox/2.1.5/jquery.fancybox.pack.js"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  



  




	





  





  

  
      <!-- UY BEGIN -->
      <script type="text/javascript" src="http://v2.uyan.cc/code/uyan.js?uid="></script>
      <!-- UY END -->
  



  
    <script type="text/javascript">
      (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>
  


  
  

  

  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
  <script>AV.initialize("kJ2sJuSJeByLioULSXrJ5CSq-9Nh9j0Va", "uBWeNxCbFEWsOVDTmAInrDq3");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  

	<!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/love.js"></script>

</body>
</html>
